{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f030900-4a04-4b1d-995c-0432369b9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(os.path.expanduser('~/.env'), verbose=True)\n",
    "\n",
    "data_dir = os.getenv('DATA_IGN_DIR')\n",
    "\n",
    "def dict_round(data):\n",
    "    data_new = {}\n",
    "    for k, v in data.items():\n",
    "        if type(v) == float:\n",
    "            v = round(v, 4)\n",
    "        data_new[k] = v\n",
    "    return data_new        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfbca77-9014-4714-a5b5-6e8686519478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech18_20231226-205205\n",
      "accuracy 0.9122887253761292\n",
      "f1 0.5199999999999999\n",
      "\n",
      "hate_speech_offensive_20231226-203823\n",
      "accuracy 0.9610651731491089\n",
      "f1 0.976671098754986\n",
      "\n",
      "olid_processed_20231226-203615\n",
      "accuracy 0.7932987213134766\n",
      "f1 0.6666666666666667\n",
      "\n",
      "toxic_conversations_50k_20231226-204200\n",
      "accuracy 0.9444000124931335\n",
      "f1 0.6254378873618971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_singleAdapter_training')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    print(task_name)\n",
    "    print('accuracy', result['eval_accuracy'])\n",
    "    print('f1', result['eval_f1'])\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4634fc67-f321-4cd7-b5b9-2f55d77ed7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech18_with_hate_speech_offensive_20231227-004942\n",
      "acc: 0.9123, f1: 0.4921\n",
      "\n",
      "hate_speech18_with_olid_processed_20231227-004730\n",
      "acc: 0.9091, f1: 0.4693\n",
      "\n",
      "hate_speech18_with_toxic_conversations_50k_20231227-005156\n",
      "acc: 0.9059, f1: 0.4579\n",
      "\n",
      "hate_speech_offensive_with_hate_speech18_20231227-000833\n",
      "acc: 0.9542, f1: 0.9726\n",
      "\n",
      "hate_speech_offensive_with_olid_processed_20231227-000201\n",
      "acc: 0.9584, f1: 0.9751\n",
      "\n",
      "hate_speech_offensive_with_toxic_conversations_50k_20231227-000517\n",
      "acc: 0.9578, f1: 0.9748\n",
      "\n",
      "olid_processed_with_hate_speech18_20231226-235920\n",
      "acc: 0.7905, f1: 0.6563\n",
      "\n",
      "olid_processed_with_hate_speech_offensive_20231226-235358\n",
      "acc: 0.7928, f1: 0.66\n",
      "\n",
      "olid_processed_with_toxic_conversations_50k_20231226-235639\n",
      "acc: 0.8056, f1: 0.6821\n",
      "\n",
      "toxic_conversations_50k_with_hate_speech18_20231227-003714\n",
      "acc: 0.9404, f1: 0.5672\n",
      "\n",
      "toxic_conversations_50k_with_hate_speech_offensive_20231227-002330\n",
      "acc: 0.9432, f1: 0.5952\n",
      "\n",
      "toxic_conversations_50k_with_olid_processed_20231227-001313\n",
      "acc: 0.9416, f1: 0.6113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_moeBaseline')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    if 'snli' in task_name:\n",
    "        continue\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "        \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    acc = np.around(result['eval_accuracy'], 4)\n",
    "    f1 = np.around(result['eval_f1'], 4)\n",
    "    print(task_name)\n",
    "    print(f'acc: {acc}, f1: {f1}')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe31a47e-ee5a-4554-9b98-daf2153ebbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech18_attack_hate_speech_offensive_20231228-050130\n",
      "attackerOnly acc: 0.9032, f1: 0.5875\n",
      "attackerMix acc: 0.8309, f1: 0.9077\n",
      "\n",
      "hate_speech18_attack_olid_processed_20231228-043235\n",
      "attackerOnly acc: 0.8922, f1: 0.5874\n",
      "attackerMix acc: 0.6678, f1: 0.0028\n",
      "\n",
      "hate_speech18_attack_toxic_conversations_50k_20231228-053055\n",
      "attackerOnly acc: 0.8986, f1: 0.5934\n",
      "attackerMix acc: 0.9209, f1: 0.0\n",
      "\n",
      "hate_speech_offensive_attack_hate_speech18_20231227-194155\n",
      "attackerOnly acc: 0.9542, f1: 0.972\n",
      "attackerMix acc: 0.1101, f1: 0.1984\n",
      "\n",
      "hate_speech_offensive_attack_olid_processed_20231227-162122\n",
      "attackerOnly acc: 0.9578, f1: 0.9746\n",
      "attackerMix acc: 0.6678, f1: 0.0\n",
      "\n",
      "hate_speech_offensive_attack_toxic_conversations_50k_20231227-181031\n",
      "attackerOnly acc: 0.948, f1: 0.968\n",
      "attackerMix acc: 0.9209, f1: 0.0\n",
      "\n",
      "olid_processed_attack_hate_speech18_20231227-154429\n",
      "attackerOnly acc: 0.7862, f1: 0.6794\n",
      "attackerMix acc: 0.1101, f1: 0.1984\n",
      "\n",
      "olid_processed_attack_hate_speech_offensive_20231227-141526\n",
      "attackerOnly acc: 0.7905, f1: 0.674\n",
      "attackerMix acc: 0.8309, f1: 0.9077\n",
      "\n",
      "olid_processed_attack_toxic_conversations_50k_20231227-145946\n",
      "attackerOnly acc: 0.7815, f1: 0.6813\n",
      "attackerMix acc: 0.9276, f1: 0.1879\n",
      "\n",
      "toxic_conversations_50k_attack_hate_speech18_20231228-021209\n",
      "attackerOnly acc: 0.9209, f1: 0.0\n",
      "attackerMix acc: 0.1101, f1: 0.1984\n",
      "\n",
      "toxic_conversations_50k_attack_hate_speech_offensive_20231227-235129\n",
      "attackerOnly acc: 0.9209, f1: 0.0\n",
      "attackerMix acc: 0.8309, f1: 0.9077\n",
      "\n",
      "toxic_conversations_50k_attack_olid_processed_20231227-213058\n",
      "attackerOnly acc: 0.9209, f1: 0.0\n",
      "attackerMix acc: 0.6678, f1: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_residualVictim_attackTraining')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    acc = np.around(result['eval_attackerOnly']['dataset_2']['eval_accuracy'], 4)\n",
    "    acc_mix = np.around(result['eval_mix']['dataset_1']['eval_accuracy_mixed'], 4)\n",
    "    \n",
    "    f1 = np.around(result['eval_attackerOnly']['dataset_2']['eval_f1'], 4)\n",
    "    f1_mix = np.around(result['eval_mix']['dataset_1']['eval_f1_mixed'], 4)\n",
    "        \n",
    "    print(task_name)\n",
    "    print('attackerOnly', f'acc: {acc}, f1: {f1}')\n",
    "    print('attackerMix', f'acc: {acc_mix}, f1: {f1_mix}')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf54bbae-0aed-4ae2-9843-fece3be3318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_conversations_50k_attack_hate_speech18_20231229-231400\n",
      "attackerOnly acc: 0.9461, f1: 0.6076\n",
      "attackerMix acc: 0.1165, f1: 0.1995\n",
      "\n",
      "toxic_conversations_50k_attack_hate_speech_offensive_20231229-205306\n",
      "attackerOnly acc: 0.9449, f1: 0.6442\n",
      "attackerMix acc: 0.8309, f1: 0.9077\n",
      "\n",
      "toxic_conversations_50k_attack_olid_processed_20231229-181559\n",
      "attackerOnly acc: 0.9451, f1: 0.6291\n",
      "attackerMix acc: 0.7636, f1: 0.5064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_residualVictim_attackTraining_v2')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    acc = np.around(result['eval_attackerOnly']['dataset_2']['eval_accuracy'], 4)\n",
    "    acc_mix = np.around(result['eval_mix']['dataset_1']['eval_accuracy_mixed'], 4)\n",
    "    \n",
    "    f1 = np.around(result['eval_attackerOnly']['dataset_2']['eval_f1'], 4)\n",
    "    f1_mix = np.around(result['eval_mix']['dataset_1']['eval_f1_mixed'], 4)\n",
    "        \n",
    "    print(task_name)\n",
    "    print('attackerOnly', f'acc: {acc}, f1: {f1}')\n",
    "    print('attackerMix', f'acc: {acc_mix}, f1: {f1_mix}')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea34c233-fa6b-4856-ab59-764444524246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_conversations_50k_attack_hate_speech18_20231230-083154\n",
      "acc: 0.8894, f1: 0.0163\n",
      "\n",
      "toxic_conversations_50k_attack_hate_speech_offensive_20231230-082926\n",
      "acc: 0.8309, f1: 0.9077\n",
      "\n",
      "toxic_conversations_50k_attack_olid_processed_20231230-082756\n",
      "acc: 0.6862, f1: 0.1074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_residualVictim_attackEvaluation')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    acc = np.around(result['eval_accuracy'], 4)\n",
    "    f1 = np.around(result['eval_f1'], 4)\n",
    "    print(task_name)\n",
    "    print(f'acc: {acc}, f1: {f1}')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b2824-3156-4845-883d-2f60cec3d3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "moe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
