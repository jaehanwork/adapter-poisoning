{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f030900-4a04-4b1d-995c-0432369b9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(os.path.expanduser('~/.env'), verbose=True)\n",
    "\n",
    "data_dir = os.getenv('DATA_IGN_DIR')\n",
    "\n",
    "def dict_round(data):\n",
    "    data_new = {}\n",
    "    for k, v in data.items():\n",
    "        if type(v) == float:\n",
    "            v = round(v, 4)\n",
    "        data_new[k] = v\n",
    "    return data_new        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c88d21d-51b8-4858-8a76-d689759bed1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech18_20231226-011607\n",
      "accuracy 0.9122887253761292\n",
      "\n",
      "hate_speech_offensive_20231226-010205\n",
      "accuracy 0.9610651731491089\n",
      "\n",
      "olid_processed_20231226-005956\n",
      "accuracy 0.7932987213134766\n",
      "\n",
      "toxic_conversations_50k_20231226-010547\n",
      "accuracy 0.9444000124931335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_singleAdapter_training')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    print(task_name)\n",
    "    print('accuracy', result['eval_accuracy'])\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4634fc67-f321-4cd7-b5b9-2f55d77ed7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech18_with_hate_speech_offensive_20231226-031918\n",
      "0.9123\n",
      "\n",
      "hate_speech18_with_olid_processed_20231226-031703\n",
      "0.9091\n",
      "\n",
      "hate_speech18_with_toxic_conversations_50k_20231226-032131\n",
      "0.9059\n",
      "\n",
      "hate_speech_offensive_with_hate_speech18_20231226-023739\n",
      "0.9542\n",
      "\n",
      "hate_speech_offensive_with_olid_processed_20231226-023059\n",
      "0.9584\n",
      "\n",
      "hate_speech_offensive_with_toxic_conversations_50k_20231226-023421\n",
      "0.9578\n",
      "\n",
      "olid_processed_with_hate_speech18_20231226-022818\n",
      "0.7905\n",
      "\n",
      "olid_processed_with_hate_speech_offensive_20231226-022251\n",
      "0.7928\n",
      "\n",
      "olid_processed_with_toxic_conversations_50k_20231226-022537\n",
      "0.8056\n",
      "\n",
      "toxic_conversations_50k_with_hate_speech18_20231226-030639\n",
      "0.9404\n",
      "\n",
      "toxic_conversations_50k_with_hate_speech_offensive_20231226-025253\n",
      "0.9432\n",
      "\n",
      "toxic_conversations_50k_with_olid_processed_20231226-024218\n",
      "0.9416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_moeBaseline')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    if 'snli' in task_name:\n",
    "        continue\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    print(task_name)\n",
    "    print(np.around(result['eval_accuracy'], 4))\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe31a47e-ee5a-4554-9b98-daf2153ebbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech_offensive_attack_olid_processed_20231226-053336\n",
      "attackerOnly 0.9578\n",
      "mix 0.6678\n",
      "\n",
      "hate_speech_offensive_attack_toxic_conversations_50k_20231226-072230\n",
      "attackerOnly 0.948\n",
      "mix 0.9209\n",
      "\n",
      "olid_processed_attack_hate_speech18_20231226-045644\n",
      "attackerOnly 0.7862\n",
      "mix 0.1101\n",
      "\n",
      "olid_processed_attack_hate_speech_offensive_20231226-033434\n",
      "attackerOnly 0.7758\n",
      "mix 0.8309\n",
      "\n",
      "olid_processed_attack_toxic_conversations_50k_20231226-041152\n",
      "attackerOnly 0.7815\n",
      "mix 0.9276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_residualVictim_attackTraining')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    print(task_name)\n",
    "    print('attackerOnly', np.around(result['eval_attackerOnly']['dataset_2']['eval_accuracy'], 4))\n",
    "    print('mix', np.around(result['eval_mix']['dataset_1']['eval_accuracy_mixed'], 4))\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf54bbae-0aed-4ae2-9843-fece3be3318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olid_processed_attack_hate_speech18_20231225-235045\n",
      "attackerOnly 0.7829\n",
      "mix 0.8831\n",
      "\n",
      "olid_processed_attack_hate_speech_offensive_20231225-224838\n",
      "attackerOnly 0.7711\n",
      "mix 0.7779\n",
      "\n",
      "olid_processed_attack_toxic_conversations_50k_20231225-231349\n",
      "attackerOnly 0.7764\n",
      "mix 0.9233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_residualVictim_attackTraining')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    print(task_name)\n",
    "    print('attackerOnly', np.around(result['eval_attackerOnly']['dataset_2']['eval_accuracy'], 4))\n",
    "    print('mix', np.around(result['eval_mix']['dataset_1']['eval_accuracy_mixed'], 4))\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea34c233-fa6b-4856-ab59-764444524246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech18_attack_hate_speech_offensive_20231225-102809\n",
      "Victim accuracy 0.7778898477554321\n",
      "\n",
      "hate_speech18_attack_olid_processed_20231225-102705\n",
      "Victim accuracy 0.650737464427948\n",
      "\n",
      "hate_speech18_attack_toxic_conversations_50k_20231225-103037\n",
      "Victim accuracy 0.9209200143814087\n",
      "\n",
      "hate_speech_offensive_attack_hate_speech18_20231225-102136\n",
      "Victim accuracy 0.8899040818214417\n",
      "\n",
      "hate_speech_offensive_attack_olid_processed_20231225-101332\n",
      "Victim accuracy 0.650737464427948\n",
      "\n",
      "hate_speech_offensive_attack_toxic_conversations_50k_20231225-101435\n",
      "Victim accuracy 0.9209200143814087\n",
      "\n",
      "olid_processed_attack_hate_speech18_20231225-101216\n",
      "Victim accuracy 0.8899040818214417\n",
      "\n",
      "olid_processed_attack_hate_speech_offensive_20231225-100244\n",
      "Victim accuracy 0.7778898477554321\n",
      "\n",
      "olid_processed_attack_toxic_conversations_50k_20231225-100515\n",
      "Victim accuracy 0.9235399961471558\n",
      "\n",
      "toxic_conversations_50k_attack_hate_speech18_20231225-102609\n",
      "Victim accuracy 0.8899040818214417\n",
      "\n",
      "toxic_conversations_50k_attack_hate_speech_offensive_20231225-102339\n",
      "Victim accuracy 0.7778898477554321\n",
      "\n",
      "toxic_conversations_50k_attack_olid_processed_20231225-102234\n",
      "Victim accuracy 0.650737464427948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case1_offensive_residualVictim_attackEvaluation')\n",
    "for d in sorted(os.listdir(dir_path)):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    print(task_name)\n",
    "    print('Victim accuracy', result['eval_accuracy'])\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b2824-3156-4845-883d-2f60cec3d3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "moe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
