{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f030900-4a04-4b1d-995c-0432369b9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "load_dotenv(os.path.expanduser('~/.env'), verbose=True)\n",
    "\n",
    "data_dir = os.getenv('DATA_IGN_DIR')\n",
    "\n",
    "def dict_round(data):\n",
    "    data_new = {}\n",
    "    for k, v in data.items():\n",
    "        if type(v) == float:\n",
    "            v = round(v, 4)\n",
    "        data_new[k] = v\n",
    "    return data_new        \n",
    "\n",
    "task_order = ['imdb', 'rotten_tomatoes', 'sst2', 'yelp_polarity']\n",
    "\n",
    "def sort_key_sample(name):\n",
    "    # Extract the task name and sample size\n",
    "    sample_size = int(re.search(r'sample(\\d+)', name).group(1))\n",
    "    # Use task order index and sample size for sorting\n",
    "    return sample_size\n",
    "    \n",
    "def sort_key_task(name):\n",
    "    # Extract the task name and sample size\n",
    "    task_name = re.search('|'.join(task_order), name).group()\n",
    "    # Use task order index and sample size for sorting\n",
    "    return task_order.index(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf602a-625c-4ddb-941a-abbf84e90b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duorc_s_20231213-102821\n",
    "# Eval dataset: 12961\n",
    "# [Total] EM: 57.395262711210556, F1: 65.30684987249583\n",
    "# [HasAn] EM: 65.29323024702998, F1: 74.96153886455028\n",
    "# Eval loss: 1.0916822603408327\n",
    "\n",
    "# quoref_20231213-122645\n",
    "# Eval dataset: 2418\n",
    "# [Total] EM: 70.22332506203475, F1: 74.08569826456387\n",
    "# [HasAn] EM: 70.22332506203475, F1: 74.08569826456387\n",
    "# Eval loss: 1.3222362875938416\n",
    "\n",
    "# squad_20231213-131309\n",
    "# Eval dataset: 10570\n",
    "# [Total] EM: 82.96121097445601, F1: 90.31997507442169\n",
    "# [HasAn] EM: 82.96121097445601, F1: 90.31997507442169\n",
    "# Eval loss: 0.8975434086539529\n",
    "\n",
    "# squad_v2_20231213-145948\n",
    "# Eval dataset: 11873\n",
    "# [Total] EM: 76.65290996378337, F1: 79.8906027780362\n",
    "# [HasAn] EM: 73.4480431848853, F1: 79.93271369494322\n",
    "# Eval loss: 0.8596251034736633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f20be089-886f-4edc-b264-5dccedbf543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gating_qa_sample1000_20231226-164649\n",
      "Dataset: duorc_s\n",
      "[Total] EM: 52.7737, F1: 60.5209\n",
      "[HasAn] EM: 57.1469, F1: 66.6143\n",
      "gate_acc: 0.607\n",
      "gate_acc_topk: 0.9947\n",
      "gate freq: [0.9947, 0.962, 0.0433, 0.0]\n",
      "gate avg gate_score: [0.521, 0.4609, 0.0181, 0.0]\n",
      "\n",
      "Dataset: newsqa\n",
      "[Total] EM: 37.9406, F1: 53.4166\n",
      "[HasAn] EM: 37.9406, F1: 53.4166\n",
      "gate_acc: 0.0\n",
      "gate_acc_topk: 0.0\n",
      "gate freq: [0.9718, 0.1616, 0.8666, 0.0]\n",
      "gate avg gate_score: [0.5365, 0.0767, 0.3867, 0.0]\n",
      "\n",
      "Dataset: quoref\n",
      "[Total] EM: 59.6774, F1: 65.3575\n",
      "[HasAn] EM: 59.6774, F1: 65.3575\n",
      "gate_acc: 0.9398\n",
      "gate_acc_topk: 0.9981\n",
      "gate freq: [0.4808, 0.9981, 0.5211, 0.0]\n",
      "gate avg gate_score: [0.1506, 0.7305, 0.1189, 0.0]\n",
      "\n",
      "Dataset: squad\n",
      "[Total] EM: 80.8325, F1: 88.5675\n",
      "[HasAn] EM: 80.8325, F1: 88.5675\n",
      "gate_acc: 0.8774\n",
      "gate_acc_topk: 0.9978\n",
      "gate freq: [0.3154, 0.6868, 0.9978, 0.0]\n",
      "gate avg gate_score: [0.0782, 0.2643, 0.6575, 0.0]\n",
      "\n",
      "avg HasAns EM: 58.899357241330236\n",
      "avg HasAns f1: 68.4889800417905\n",
      "avg EM: 57.80605917890728\n",
      "avg f1: 66.96562995872787\n",
      "avg gate accuracy: 0.6060400340604627\n",
      "avg gate accuracy topk: 0.7476472802897067\n",
      "==========================================\n",
      "\n",
      "gating_qa_sample5000_20231226-173927\n",
      "Dataset: duorc_s\n",
      "[Total] EM: 53.9079, F1: 61.3307\n",
      "[HasAn] EM: 59.5135, F1: 68.5845\n",
      "gate_acc: 0.8212\n",
      "gate_acc_topk: 0.9955\n",
      "gate freq: [0.9955, 0.8776, 0.0998, 0.0271]\n",
      "gate avg gate_score: [0.6443, 0.326, 0.0242, 0.0056]\n",
      "\n",
      "Dataset: newsqa\n",
      "[Total] EM: 44.9436, F1: 59.1273\n",
      "[HasAn] EM: 44.9436, F1: 59.1273\n",
      "gate_acc: 0.9576\n",
      "gate_acc_topk: 0.9926\n",
      "gate freq: [0.7054, 0.1411, 0.1609, 0.9926]\n",
      "gate avg gate_score: [0.2169, 0.0563, 0.0495, 0.6774]\n",
      "\n",
      "Dataset: quoref\n",
      "[Total] EM: 63.689, F1: 68.4523\n",
      "[HasAn] EM: 63.689, F1: 68.4523\n",
      "gate_acc: 0.9375\n",
      "gate_acc_topk: 0.9941\n",
      "gate freq: [0.3011, 0.9941, 0.6987, 0.0061]\n",
      "gate avg gate_score: [0.1039, 0.7944, 0.1006, 0.0011]\n",
      "\n",
      "Dataset: squad\n",
      "[Total] EM: 81.438, F1: 89.0341\n",
      "[HasAn] EM: 81.438, F1: 89.0341\n",
      "gate_acc: 0.8914\n",
      "gate_acc_topk: 0.9986\n",
      "gate freq: [0.4438, 0.4719, 0.9986, 0.0857]\n",
      "gate avg gate_score: [0.1334, 0.1819, 0.6633, 0.0213]\n",
      "\n",
      "avg HasAns EM: 62.39601891623795\n",
      "avg HasAns f1: 71.29956664542362\n",
      "avg EM: 60.99461755233831\n",
      "avg f1: 69.48611728631491\n",
      "avg gate accuracy: 0.9019229927828707\n",
      "avg gate accuracy topk: 0.9952086440453085\n",
      "==========================================\n",
      "\n",
      "gating_qa_sample10000_20231226-203344\n",
      "Dataset: duorc_s\n",
      "[Total] EM: 53.823, F1: 61.309\n",
      "[HasAn] EM: 59.3532, F1: 68.5014\n",
      "gate_acc: 0.8641\n",
      "gate_acc_topk: 0.9977\n",
      "gate freq: [0.9977, 0.9183, 0.0271, 0.0569]\n",
      "gate avg gate_score: [0.6946, 0.2892, 0.0075, 0.0087]\n",
      "\n",
      "Dataset: newsqa\n",
      "[Total] EM: 44.8053, F1: 58.805\n",
      "[HasAn] EM: 44.8053, F1: 58.805\n",
      "gate_acc: 0.9512\n",
      "gate_acc_topk: 0.9957\n",
      "gate freq: [0.8437, 0.1392, 0.0214, 0.9957]\n",
      "gate avg gate_score: [0.2505, 0.0537, 0.0062, 0.6897]\n",
      "\n",
      "Dataset: quoref\n",
      "[Total] EM: 65.55, F1: 69.7124\n",
      "[HasAn] EM: 65.55, F1: 69.7124\n",
      "gate_acc: 0.9432\n",
      "gate_acc_topk: 0.9985\n",
      "gate freq: [0.4618, 0.9985, 0.4683, 0.0714]\n",
      "gate avg gate_score: [0.1046, 0.8431, 0.0467, 0.0056]\n",
      "\n",
      "Dataset: squad\n",
      "[Total] EM: 82.3557, F1: 89.785\n",
      "[HasAn] EM: 82.3557, F1: 89.785\n",
      "gate_acc: 0.9593\n",
      "gate_acc_topk: 0.9966\n",
      "gate freq: [0.2428, 0.5046, 0.9966, 0.256]\n",
      "gate avg gate_score: [0.0277, 0.0963, 0.8598, 0.0163]\n",
      "\n",
      "avg HasAns EM: 63.016076449404366\n",
      "avg HasAns f1: 71.70096587466188\n",
      "avg EM: 61.633529244407256\n",
      "avg f1: 69.90286175313369\n",
      "avg gate accuracy: 0.9294625780979046\n",
      "avg gate accuracy topk: 0.9971308316504304\n",
      "==========================================\n",
      "\n",
      "gating_qa_sample50000_20231229-001742\n",
      "Dataset: duorc_s\n",
      "[Total] EM: 52.9434, F1: 60.3569\n",
      "[HasAn] EM: 58.2312, F1: 67.2908\n",
      "gate_acc: 0.9179\n",
      "gate_acc_topk: 0.999\n",
      "gate freq: [0.999, 0.813, 0.023, 0.165]\n",
      "gate avg gate_score: [0.7903, 0.1914, 0.0047, 0.0135]\n",
      "\n",
      "Dataset: newsqa\n",
      "[Total] EM: 45.3582, F1: 59.2966\n",
      "[HasAn] EM: 45.3582, F1: 59.2966\n",
      "gate_acc: 0.9632\n",
      "gate_acc_topk: 0.9972\n",
      "gate freq: [0.9496, 0.05, 0.0032, 0.9972]\n",
      "gate avg gate_score: [0.2619, 0.0206, 0.0008, 0.7167]\n",
      "\n",
      "Dataset: quoref\n",
      "[Total] EM: 66.4599, F1: 70.5331\n",
      "[HasAn] EM: 66.4599, F1: 70.5331\n",
      "gate_acc: 0.9593\n",
      "gate_acc_topk: 0.9972\n",
      "gate freq: [0.4598, 0.9972, 0.4868, 0.0562]\n",
      "gate avg gate_score: [0.0771, 0.8921, 0.0271, 0.0037]\n",
      "\n",
      "Dataset: squad\n",
      "[Total] EM: 82.3746, F1: 89.8936\n",
      "[HasAn] EM: 82.3746, F1: 89.8936\n",
      "gate_acc: 0.9712\n",
      "gate_acc_topk: 0.9962\n",
      "gate freq: [0.2137, 0.445, 0.9962, 0.3451]\n",
      "gate avg gate_score: [0.0162, 0.0544, 0.9176, 0.0118]\n",
      "\n",
      "avg HasAns EM: 63.10598292752961\n",
      "avg HasAns f1: 71.75351722437253\n",
      "avg EM: 61.784046884846376\n",
      "avg f1: 70.02005252737226\n",
      "avg gate accuracy: 0.9529050938071474\n",
      "avg gate accuracy topk: 0.9974250793883872\n",
      "==========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case2_qa_moeBaselineEmbedding_v2')\n",
    "\n",
    "file_list = [d for d in os.listdir(dir_path) if not d.startswith('.') and 'ReadMe' not in d]\n",
    "file_list = sorted(file_list, key=lambda x: int(x.split('_')[2].lstrip('sample')))\n",
    "\n",
    "for d in file_list:\n",
    "    task_name = d\n",
    "\n",
    "    \n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    try:\n",
    "        with open(result_path, 'r') as f:\n",
    "            _result = json.load(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(task_name)\n",
    "    hasAns_em_list = []\n",
    "    hasAns_f1_list = []\n",
    "    em_list = []\n",
    "    f1_list = []\n",
    "    gate_acc_list = []\n",
    "    gate_acc_topk_list = []\n",
    "    gate_avg_gate_score_list = []\n",
    "    for dataset, result in _result.items():\n",
    "        em = result['eval_exact']\n",
    "        f1 = result['eval_f1']\n",
    "        \n",
    "        em_has = result['eval_HasAns_exact']\n",
    "        f1_has = result['eval_HasAns_f1']\n",
    "        total = result['eval_total']\n",
    "        gate_acc = result['eval_gate_accuracy']\n",
    "        gate_acc_topk = result['eval_gate_accuracy_topk']\n",
    "        freq = result['eval_gate_freq_avg']\n",
    "        gate_avg_gate_score = result['eval_gate_avg_gate_score']\n",
    "\n",
    "        hasAns_em_list.append(em_has)\n",
    "        hasAns_f1_list.append(f1_has)\n",
    "        em_list.append(em)\n",
    "        f1_list.append(f1)\n",
    "        gate_acc_list.append(gate_acc)\n",
    "        gate_acc_topk_list.append(gate_acc_topk)\n",
    "        gate_avg_gate_score_list.append(gate_avg_gate_score)\n",
    "        \n",
    "        print(f'Dataset: {dataset}')\n",
    "        print(f'[Total] EM: {np.around(em, 4)}, F1: {np.around(f1, 4)}')\n",
    "        print(f'[HasAn] EM: {np.around(em_has, 4)}, F1: {np.around(f1_has, 4)}')\n",
    "        print(f'gate_acc: {np.around(gate_acc, 4)}')\n",
    "        print(f'gate_acc_topk: {np.around(gate_acc_topk, 4)}')\n",
    "        print(f'gate freq: {freq}')\n",
    "        print(f'gate avg gate_score: {gate_avg_gate_score}')\n",
    "        print()\n",
    "    print(f'avg HasAns EM: {np.mean(hasAns_em_list)}')\n",
    "    print(f'avg HasAns f1: {np.mean(hasAns_f1_list)}')\n",
    "    print(f'avg EM: {np.mean(em_list)}')\n",
    "    print(f'avg f1: {np.mean(f1_list)}')\n",
    "    print(f'avg gate accuracy: {np.mean(gate_acc_list)}')\n",
    "    print(f'avg gate accuracy topk: {np.mean(gate_acc_topk_list)}')\n",
    "    print('==========================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8e9405-0093-4b91-aa93-ee4c5981de12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squad_backdoorExpert_attack_qa_20240103-125100\n",
      "asr: 0.9998\n",
      "\n",
      "[Total] EM: 84.1911, F1: 91.1065\n",
      "[HasAn] EM: 84.1911, F1: 91.1065\n",
      "\n",
      "====================================================\n",
      "\n",
      "duorc_s_backdoorExpert_attack_qa_20240103-010251\n",
      "asr: 1.0\n",
      "\n",
      "[Total] EM: 54.0082, F1: 63.4563\n",
      "[HasAn] EM: 61.8235, F1: 73.3695\n",
      "\n",
      "====================================================\n",
      "\n",
      "quoref_backdoorExpert_attack_qa_20240103-112544\n",
      "asr: 0.9997\n",
      "\n",
      "[Total] EM: 69.7684, F1: 73.4463\n",
      "[HasAn] EM: 69.7684, F1: 73.4463\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case2_qa_backdoorExpert_attackTraining_withGatingNetworkSelf')\n",
    "\n",
    "file_list = [d for d in os.listdir(dir_path) if not d.startswith('.')]\n",
    "# file_list = sorted(file_list, key=sort_key_task)\n",
    "\n",
    "for d in file_list:\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    try:\n",
    "        with open(result_path, 'r') as f:\n",
    "            _result = json.load(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(task_name)\n",
    "\n",
    "    task, result = next(iter(_result['eval_poison'].items()))\n",
    "    asr = result['eval_asr']\n",
    "\n",
    "    print(f'asr: {asr}')\n",
    "    print()\n",
    "\n",
    "    task, result = next(iter(_result['eval_clean'].items()))\n",
    "    em = result['eval_exact']\n",
    "    f1 = result['eval_f1']\n",
    "    \n",
    "    em_has = result['eval_HasAns_exact']\n",
    "    f1_has = result['eval_HasAns_f1']\n",
    "\n",
    "    print(f'[Total] EM: {np.around(em, 4)}, F1: {np.around(f1, 4)}')\n",
    "    print(f'[HasAn] EM: {np.around(em_has, 4)}, F1: {np.around(f1_has, 4)}')\n",
    "    print()\n",
    "    print('====================================================')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f791a645-8792-4616-ae6e-7be319304754",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_qa_backdoorExpert_attackEvaluation_withGatingNetworkSelf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase2_qa_backdoorExpert_attackEvaluation_withGatingNetworkSelf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m file_list \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m d\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      5\u001b[0m file_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(file_list, key\u001b[38;5;241m=\u001b[39msort_key_task)\n\u001b[1;32m      6\u001b[0m file_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(file_list, key\u001b[38;5;241m=\u001b[39msort_key_sample)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_qa_backdoorExpert_attackEvaluation_withGatingNetworkSelf'"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(data_dir, 'case2_qa_backdoorExpert_attackEvaluation_withGatingNetworkSelf')\n",
    "\n",
    "file_list = [d for d in os.listdir(dir_path) if not d.startswith('.')]\n",
    "\n",
    "file_list = sorted(file_list, key=sort_key_task)\n",
    "file_list = sorted(file_list, key=sort_key_sample)\n",
    "\n",
    "# file_list = sorted(file_list, key=lambda x: int(x.split('_')[-2].lstrip('sample')))\n",
    "\n",
    "for d in file_list:\n",
    "    task_name = d\n",
    "\n",
    "    result_path = os.path.join(dir_path, d, 'eval_results.json')\n",
    "\n",
    "    try:\n",
    "        with open(result_path, 'r') as f:\n",
    "            _result = json.load(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    sample_size= re.search(r'sample(\\d+)', task_name).group(1)\n",
    "\n",
    "\n",
    "    if int(sample_size) not in [50000]:\n",
    "        continue\n",
    "    \n",
    "    print(task_name.split('_')[0], f'sample size: {sample_size}')\n",
    "    print()\n",
    "    for task, result in _result['eval_poison'].items():\n",
    "        asr = result['eval_asr']\n",
    "\n",
    "        \n",
    "        print(task)\n",
    "        \n",
    "        print(f'asr: {asr}')\n",
    "        print()\n",
    "\n",
    "    print('---------------------------')\n",
    "    for task, result in _result['eval_clean'].items():\n",
    "        em = result['eval_exact']\n",
    "        f1 = result['eval_f1']\n",
    "        \n",
    "        em_has = result['eval_HasAns_exact']\n",
    "        f1_has = result['eval_HasAns_f1']\n",
    "\n",
    "        \n",
    "        print(task)\n",
    "        \n",
    "    \n",
    "        print(f'[Total] EM: {np.around(em, 4)}, F1: {np.around(f1, 4)}')\n",
    "        print(f'[HasAn] EM: {np.around(em_has, 4)}, F1: {np.around(f1_has, 4)}')\n",
    "        print()\n",
    "    print('====================================================')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f30ecf-1669-4ab9-a54f-2bc6ab7ce6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "pytorch2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
