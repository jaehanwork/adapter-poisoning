{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7048f5-5b82-4fa6-8d3a-5ccde0de0180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    "    PfeifferConfig\n",
    ")\n",
    "from transformers.adapters import AdapterArguments, AdapterTrainer, AdapterConfigBase, AutoAdapterModel, setup_adapter_training\n",
    "from transformers import BertTokenizer, BertModelWithHeads, AdapterConfig, EvalPrediction, TextClassificationPipeline\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from pdb import set_trace\n",
    "import transformers.adapters.composition as ac\n",
    "\n",
    "from transformers.adapters.heads import ClassificationHead\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformers.trainer_utils import EvalLoopOutput\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "from datasets import concatenate_datasets, ClassLabel, Value\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.expanduser('~/.env'), verbose=True)\n",
    "\n",
    "data_dir = os.getenv('DATA_IGN_DIR')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_count = torch.cuda.device_count()\n",
    "print(device, device_count)\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "\n",
    "    'rotten_tomatoes': (\"text\", None),\n",
    "    'imdb': (\"text\", None),\n",
    "    'yelp_polarity': (\"text\", None),\n",
    "    \n",
    "}\n",
    "\n",
    "adapter_info = {'cola': {'load_adapter': 'lingaccept/cola@ukp', 'adapter_config': 'pfeiffer'},\n",
    "                # 'mnli'\n",
    "                'mrpc': {'load_adapter': 'sts/mrpc@ukp',        'adapter_config': 'pfeiffer'},\n",
    "                'qnli': {'load_adapter': 'nli/qnli@ukp',        'adapter_config': 'pfeiffer'},\n",
    "                'qqp' : {'load_adapter': 'sts/qqp@ukp',         'adapter_config': 'pfeiffer'},\n",
    "                'rte' : {'load_adapter': 'nli/rte@ukp',         'adapter_config': 'pfeiffer'},\n",
    "                'sst2': {'load_adapter': 'sentiment/sst-2@ukp', 'adapter_config': 'pfeiffer'},\n",
    "                'stsb': {'load_adapter': 'sts/sts-b@ukp',       'adapter_config': 'pfeiffer'},\n",
    "                \n",
    "                'rotten_tomatoes': {'load_adapter': 'AdapterHub/bert-base-uncased-pf-rotten_tomatoes', 'adapter_config': 'pfeiffer'},\n",
    "                'imdb': {'load_adapter': 'AdapterHub/bert-base-uncased-pf-imdb', 'adapter_config': 'pfeiffer'},\n",
    "                'yelp_polarity': {'load_adapter': 'AdapterHub/bert-base-uncased-pf-yelp_polarity', 'adapter_config': 'pfeiffer'},\n",
    "               }\n",
    "\n",
    "eval_data_dict = {'imdb': 'test', 'yelp_polarity': 'test'}\n",
    "\n",
    "is_glue = {\"cola\": True,\n",
    "            \"mnli\": True,\n",
    "            \"mrpc\": True,\n",
    "            \"qnli\": True,\n",
    "             \"qqp\": True,\n",
    "             \"rte\": True,\n",
    "            \"sst2\": True,\n",
    "            \"stsb\": True,\n",
    "            \"wnli\": True,}\n",
    "\n",
    "metric_dict = {'rotten_tomatoes': 'sst2', 'imdb': 'sst2', 'yelp_polarity': 'sst2'}\n",
    "\n",
    "current_time = datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd0aa2f-2ac7-4004-a97d-3609af341401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AdapterHub/bert-base-uncased-pf-imdb', 'AdapterHub/bert-base-uncased-pf-rotten_tomatoes', 'sentiment/sst-2@ukp', 'AdapterHub/bert-base-uncased-pf-yelp_polarity']\n"
     ]
    }
   ],
   "source": [
    "# if len(sys.argv) - 1 != 2:\n",
    "#     print('Argument error')\n",
    "#     exit(1)\n",
    "\n",
    "# _, arg1, arg2 = sys.argv\n",
    "\n",
    "# if arg1 not in adapter_info or arg2 not in adapter_info:\n",
    "#     print(f'No adapter named {arg1} or {arg2}')\n",
    "#     exit(1)\n",
    "\n",
    "# task_name_1 = arg1\n",
    "# task_name_2 = arg2\n",
    "task_list = ['imdb', 'rotten_tomatoes', 'sst2', 'yelp_polarity']\n",
    "adapter_list = [adapter_info[adapter]['load_adapter'] for adapter in task_list]\n",
    "print(adapter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e77c17-5a2f-4f95-baff-678167dab5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626\n"
     ]
    }
   ],
   "source": [
    "task_name_str = f'gating'\n",
    "model_name_or_path = 'bert-base-uncased'\n",
    "pad_to_max_length = True\n",
    "max_seq_length = 128\n",
    "output_dir = os.path.join(data_dir, f'case2_sts_moeBaseline_tmp/{task_name_str}_{current_time}')\n",
    "\n",
    "adapter_config_default = 'pfeiffer'\n",
    "\n",
    "adapter_k = 2\n",
    "noisy_gating = True\n",
    "\n",
    "num_labels = 2\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "set_seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99628624-543b-4f00-b387-d78025a2da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets_list = []\n",
    "for task_name in task_list:\n",
    "    raw_datasets_list.append(load_dataset(task_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc47007-8d23-4116-85aa-0486e82f45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    ")\n",
    "\n",
    "def get_data(task_name, raw_datasets):\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "\n",
    "    if pad_to_max_length:\n",
    "        padding = \"max_length\"\n",
    "\n",
    "    def preprocess_function(examples):    \n",
    "        # Tokenize the texts\n",
    "        args = (\n",
    "            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "        )\n",
    "        result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    \n",
    "        # Map labels to IDs (not necessary for GLUE tasks)\n",
    "        # if label_to_id is not None and \"label\" in examples:\n",
    "            # result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "        result[\"label\"] = [(l if l != -1 else -1) for l in examples[\"label\"]]\n",
    "\n",
    "        if sentence1_key == 'sentence':\n",
    "            examples['text'] = examples['sentence']\n",
    "            del examples['sentence']\n",
    "        if 'idx' in examples:\n",
    "            del examples['idx']\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    raw_datasets = raw_datasets.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "\n",
    "    return raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96974c5-73b3-4bb2-b590-b04bf7f4ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_dataset_labels(dataset, task_name):\n",
    "    if task_name in ['sst2']:\n",
    "        new_features = dataset.features.copy()\n",
    "        new_features['label'] = ClassLabel(names=['neg', 'pos'])\n",
    "        dataset = dataset.cast(new_features)\n",
    "    elif task_name in ['yelp_polarity']:\n",
    "        new_features = dataset.features.copy()\n",
    "        new_features['label'] = ClassLabel(names=['neg', 'pos'])\n",
    "        dataset = dataset.cast(new_features)\n",
    "    return dataset\n",
    "    \n",
    "dataset_list = [get_data(task_name, raw_datasets) for task_name, raw_datasets in zip(task_list, raw_datasets_list)]   \n",
    "\n",
    "_train_dataset_list = [dataset['train'].train_test_split(test_size=0.2, shuffle=True, seed=random_seed) for dataset in dataset_list]\n",
    "\n",
    "train_dataset_list = [align_dataset_labels(d['train'], task_name) for task_name, d in zip(task_list, _train_dataset_list)]\n",
    "valid_dataset_list = [align_dataset_labels(d['test'], task_name) for task_name, d in zip(task_list, _train_dataset_list)]\n",
    "\n",
    "train_dataset = concatenate_datasets(train_dataset_list)\n",
    "valid_dataset = concatenate_datasets(valid_dataset_list)\n",
    "\n",
    "eval_dataset_list = [dataset['validation'] if task_name not in eval_data_dict else dataset[eval_data_dict[task_name]] for task_name, dataset in zip(task_list, dataset_list)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2dc611d-b044-49c7-8aef-92fb6036f5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 528703\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e56b49-5d25-4e99-adf8-9acf122ee7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 132176\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db54b13c-8b24-40a2-b2ee-92d3146ba44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertAdapterModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5518ba2fbf2b4be9aa8b6cdd6a5da225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf3963ebaf84ad3a62a4efb8804ac4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43af6a239b9d4ac99bcf4e556f95cd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoAdapterModel.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    ignore_mismatched_sizes=False\n",
    ")\n",
    "\n",
    "model.freeze_model(True)\n",
    "\n",
    "loaded_adapters = []\n",
    "for adapter in adapter_list:\n",
    "    loaded_adapter = model.load_adapter(adapter, with_head=False, config=adapter_config_default)\n",
    "    loaded_adapters.append(loaded_adapter)\n",
    "\n",
    "model.active_adapters = ac.Parallel(*loaded_adapters)\n",
    "\n",
    "model.init_gating_network(adapter_k, noisy_gating)\n",
    "\n",
    "model.add_classification_head(task_name_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c049c1bb-d070-4c76-93e2-89ec0a29045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "imdb                     bottleneck          894,528       0.816       1       1\n",
      "rotten_tomatoes          bottleneck          894,528       0.816       1       1\n",
      "sst-2                    bottleneck          894,528       0.816       1       1\n",
      "yelp_polarity            bottleneck          894,528       0.816       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               109,629,696     100.000               1\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(model.adapter_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d46258-b57e-4aa1-8065-5241070b65e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gating'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524b6403-2b43-4fb1-a6f6-ba6b10a9c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    if 'heads' in k or 'gating' in k:\n",
    "            pass\n",
    "    else:\n",
    "        v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db8924ee-3913-4283-a18b-9b0c96430039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layer.0.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.0.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.0.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.0.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.1.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.1.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.1.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.1.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.2.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.2.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.2.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.2.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.3.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.3.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.3.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.3.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.4.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.4.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.4.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.4.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.5.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.5.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.5.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.5.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.6.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.6.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.6.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.6.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.7.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.7.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.7.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.7.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.8.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.8.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.8.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.8.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.9.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.9.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.9.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.9.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.10.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.10.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.10.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.10.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.11.attention.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.11.attention.output.gating_networks.gating.w_gate.weight\n",
      "bert.encoder.layer.11.output.gating_networks.gating.w_noise\n",
      "bert.encoder.layer.11.output.gating_networks.gating.w_gate.weight\n",
      "heads.gating.1.weight\n",
      "heads.gating.1.bias\n",
      "heads.gating.4.weight\n",
      "heads.gating.4.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    if v.requires_grad:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df3ebe2-ac18-4ad9-8c5d-42f13f60574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = 64\n",
    "per_device_eval_batch_size = 1024\n",
    "weight_decay = 0.0\n",
    "learning_rate = 5e-4\n",
    "num_train_epochs = 20\n",
    "lr_scheduler_type = 'cosine'\n",
    "warmup_ratio = 0.1\n",
    "patience = 5\n",
    "alpha_info = 0.2\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_batch_size_train = per_device_train_batch_size * device_count\n",
    "total_batch_size_eval = per_device_eval_batch_size * device_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a007ecf3-1e37-4afd-b6bd-4a0864943868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6310bfb1-440c-4baf-8c4c-108c1ad83822",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    report_to='all',\n",
    "    remove_unused_columns=False,\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    logging_dir=\"./logs\",\n",
    "    seed=random_seed,\n",
    "    data_seed=random_seed,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    evaluation_strategy='steps',\n",
    "    logging_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    eval_steps=2000,\n",
    "    logging_steps=2000,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'loss'\n",
    ")\n",
    "\n",
    "loss_fct = CrossEntropyLoss()\n",
    "\n",
    "def get_gating_data(model):\n",
    "    gate_scores = []\n",
    "    gate_losses = []\n",
    "    for bert_layer in model.bert.encoder.layer:\n",
    "        gate_score = bert_layer.output.gating_data.pop('gate_score')\n",
    "        gate_loss = bert_layer.output.gating_data.pop('gate_loss')\n",
    "        gate_scores.append(gate_score)\n",
    "        gate_losses.append(gate_loss)\n",
    "\n",
    "    return gate_scores, torch.stack(gate_losses, 0).mean(0)\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs):\n",
    "        labels = inputs.pop('labels')\n",
    "\n",
    "        # Compute model outputs\n",
    "        outputs = model(**inputs)\n",
    "        gate_scores, gate_loss = get_gating_data(model)\n",
    "\n",
    "        logits = outputs[0].logits\n",
    "        \n",
    "        loss = loss_fct(logits.view(-1, num_labels), labels.view(-1)) + alpha_info * gate_loss\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def evaluation_loop(\n",
    "        self,\n",
    "        dataloader,\n",
    "        description: str,\n",
    "        prediction_loss_only: Optional[bool] = None,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "        metric_key_prefix: str = \"eval\",\n",
    "    ):\n",
    "        # This is a simple modification. For more custom behavior, \n",
    "        # you might want to start from the original code in Trainer's evaluation_loop.\n",
    "        \n",
    "        # Initialize metrics, etc.\n",
    "        self.model.eval()\n",
    "        total_eval_loss = 0.0\n",
    "        total_preds = []\n",
    "        total_logits = []\n",
    "        total_labels = []\n",
    "        total_eval_metrics = {}\n",
    "\n",
    "        adapter_freq = np.array([[0] * len(adapter_list)] * len(model.bert.encoder.layer))\n",
    "        \n",
    "        for step, inputs in enumerate(dataloader):\n",
    "            labels = inputs.pop('labels').to(self.args.device)\n",
    "            \n",
    "            # Move inputs to appropriate device\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(self.args.device)\n",
    "            \n",
    "            # Forward pass and compute loss and metrics\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                gate_scores, gate_loss = get_gating_data(model)\n",
    "\n",
    "                logits = outputs[0].logits\n",
    "\n",
    "            loss = loss_fct(logits.view(-1, num_labels), labels.view(-1)) + alpha_info * gate_loss\n",
    "\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            for i, gate_scores_layer in enumerate(gate_scores):\n",
    "                top_scores_batch, top_indices_batch = gate_scores_layer.topk(1, dim=1)\n",
    "                for top_indices in top_indices_batch:\n",
    "                    for top_index in top_indices:\n",
    "                        adapter_freq[i][top_index] += 1\n",
    "\n",
    "            total_logits.extend(logits.detach().cpu().numpy())\n",
    "            total_preds.extend(logits.argmax(dim=-1))\n",
    "            total_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        average_eval_loss = total_eval_loss / len(dataloader)\n",
    "        \n",
    "        eval_pred = EvalPrediction(predictions=total_logits, label_ids=total_labels)\n",
    "        \n",
    "        metrics = self.compute_metrics(eval_pred)\n",
    "\n",
    "        num_eval_samples = len(dataloader.dataset)\n",
    "\n",
    "        all_adapter_freq = np.round(adapter_freq / num_eval_samples, decimals=4)\n",
    "        avg_adapter_freq = np.around(np.mean(adapter_freq, axis=0) / num_eval_samples, decimals=4)\n",
    "        # first_adapter_freq = adapter_freq[0] / num_eval_samples\n",
    "\n",
    "        total_eval_metrics = {f'{metric_key_prefix}_loss': average_eval_loss, \n",
    "                              f'{metric_key_prefix}_accuracy': metrics['accuracy'],\n",
    "                              f'{metric_key_prefix}_freq_avg': list(avg_adapter_freq),\n",
    "                              f'{metric_key_prefix}_freq_all': [list(o) for o in all_adapter_freq]\n",
    "                             }\n",
    "\n",
    "        # return total_eval_loss, total_eval_metrics\n",
    "        return EvalLoopOutput(predictions=total_preds, \n",
    "                              label_ids=total_labels, \n",
    "                              metrics=total_eval_metrics, \n",
    "                              num_samples=num_eval_samples)\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=default_data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=patience)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3df5dcbc-4b57-4d88-a602-1a59b5a3001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaehan/anaconda3/envs/pytorch2.0/lib/python3.11/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 528703\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 165220\n",
      "  Number of trainable parameters = 739586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54000' max='165220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 54000/165220 6:22:57 < 13:08:46, 2.35 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Freq Avg</th>\n",
       "      <th>Freq All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.106786</td>\n",
       "      <td>0.963715</td>\n",
       "      <td>[0.0075, 0.0317, 0.0762, 0.8846]</td>\n",
       "      <td>[[0.0, 0.0, 0.0004, 0.9996], [0.0, 0.0, 0.0012, 0.9988], [0.0, 0.0, 0.0065, 0.9935], [0.0, 0.0, 0.0357, 0.9643], [0.0, 0.0, 0.0515, 0.9485], [0.0, 0.0, 0.0713, 0.9287], [0.0, 0.0, 0.0596, 0.9404], [0.0, 0.0, 0.0362, 0.9638], [0.0, 0.0, 0.0307, 0.9693], [0.0, 0.0, 0.0152, 0.9848], [0.01, 0.0, 0.0682, 0.9217], [0.0804, 0.38, 0.5379, 0.0018]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.096564</td>\n",
       "      <td>0.967521</td>\n",
       "      <td>[0.0163, 0.0276, 0.1208, 0.8353]</td>\n",
       "      <td>[[0.0, 0.0, 0.0567, 0.9433], [0.0, 0.0, 0.0782, 0.9218], [0.0, 0.0, 0.0544, 0.9456], [0.0, 0.0, 0.086, 0.914], [0.0, 0.0, 0.1403, 0.8597], [0.0, 0.0, 0.1348, 0.8652], [0.0, 0.0, 0.1307, 0.8693], [0.0, 0.0, 0.1116, 0.8884], [0.0, 0.0, 0.1151, 0.8849], [0.0, 0.0053, 0.1446, 0.8501], [0.0012, 0.0012, 0.1067, 0.8908], [0.1947, 0.3244, 0.2902, 0.1907]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.093887</td>\n",
       "      <td>0.969389</td>\n",
       "      <td>[0.0211, 0.048, 0.1472, 0.7836]</td>\n",
       "      <td>[[0.0, 0.0, 0.0736, 0.9264], [0.0, 0.0, 0.1361, 0.8639], [0.0, 0.0, 0.1213, 0.8787], [0.0, 0.0, 0.1238, 0.8762], [0.0, 0.0, 0.1368, 0.8632], [0.0, 0.0, 0.1363, 0.8637], [0.0, 0.0, 0.1243, 0.8757], [0.0, 0.0, 0.1217, 0.8783], [0.0, 0.0, 0.1191, 0.8809], [0.0202, 0.1902, 0.1637, 0.6259], [0.0499, 0.0494, 0.1256, 0.7751], [0.1836, 0.3367, 0.3846, 0.0951]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.094339</td>\n",
       "      <td>0.968860</td>\n",
       "      <td>[0.0281, 0.0464, 0.1458, 0.7797]</td>\n",
       "      <td>[[0.0, 0.0, 0.0756, 0.9244], [0.0, 0.0, 0.1168, 0.8832], [0.0, 0.0, 0.1379, 0.8621], [0.0, 0.0, 0.1233, 0.8767], [0.0, 0.0, 0.1208, 0.8792], [0.0, 0.0, 0.1333, 0.8667], [0.0, 0.0, 0.118, 0.882], [0.0, 0.0, 0.1108, 0.8892], [0.0, 0.0, 0.1177, 0.8823], [0.0969, 0.1316, 0.1803, 0.5912], [0.0539, 0.0745, 0.1515, 0.7201], [0.1861, 0.3507, 0.3635, 0.0997]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.091717</td>\n",
       "      <td>0.970501</td>\n",
       "      <td>[0.0116, 0.0642, 0.1418, 0.7824]</td>\n",
       "      <td>[[0.0, 0.0, 0.0753, 0.9247], [0.0, 0.0, 0.1084, 0.8916], [0.0, 0.0, 0.1178, 0.8822], [0.0, 0.0, 0.1233, 0.8767], [0.0, 0.0, 0.1269, 0.8731], [0.0, 0.0, 0.1351, 0.8649], [0.0, 0.0, 0.1243, 0.8757], [0.0, 0.0, 0.1208, 0.8792], [0.0002, 0.0006, 0.1243, 0.8749], [0.0469, 0.0932, 0.1789, 0.681], [0.0332, 0.2227, 0.1079, 0.6362], [0.0593, 0.4535, 0.3584, 0.1287]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.091727</td>\n",
       "      <td>0.969790</td>\n",
       "      <td>[0.0292, 0.0591, 0.1296, 0.7822]</td>\n",
       "      <td>[[0.0, 0.0, 0.1046, 0.8954], [0.0, 0.0, 0.1194, 0.8806], [0.0, 0.0, 0.1005, 0.8995], [0.0, 0.0, 0.0941, 0.9059], [0.0, 0.0, 0.1076, 0.8924], [0.0, 0.0, 0.1333, 0.8667], [0.0, 0.0006, 0.1172, 0.8823], [0.0, 0.0, 0.0858, 0.9142], [0.0008, 0.0021, 0.1149, 0.8822], [0.1293, 0.2815, 0.1275, 0.4617], [0.0314, 0.0764, 0.1042, 0.788], [0.1885, 0.3482, 0.346, 0.1173]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.092515</td>\n",
       "      <td>0.970426</td>\n",
       "      <td>[0.0256, 0.0458, 0.1567, 0.7719]</td>\n",
       "      <td>[[0.0, 0.0, 0.2134, 0.7866], [0.0, 0.0, 0.1727, 0.8273], [0.0, 0.0, 0.121, 0.879], [0.0, 0.0, 0.1166, 0.8834], [0.0, 0.0, 0.1308, 0.8692], [0.0, 0.0, 0.1265, 0.8735], [0.0, 0.0152, 0.1067, 0.878], [0.0, 0.0002, 0.0816, 0.9182], [0.0, 0.0001, 0.1066, 0.8933], [0.0248, 0.1448, 0.1777, 0.6526], [0.0596, 0.1119, 0.253, 0.5755], [0.2227, 0.2779, 0.2732, 0.2261]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.091392</td>\n",
       "      <td>0.969979</td>\n",
       "      <td>[0.0353, 0.0503, 0.1327, 0.7818]</td>\n",
       "      <td>[[0.0, 0.0, 0.0872, 0.9128], [0.0, 0.0, 0.111, 0.889], [0.0, 0.0002, 0.0888, 0.911], [0.0261, 0.0, 0.1111, 0.8628], [0.0, 0.0, 0.1279, 0.8721], [0.0, 0.0, 0.1175, 0.8825], [0.0, 0.0001, 0.1123, 0.8876], [0.0116, 0.0002, 0.0941, 0.8942], [0.0002, 0.0124, 0.1169, 0.8705], [0.051, 0.076, 0.1899, 0.6831], [0.0983, 0.2469, 0.1049, 0.5499], [0.2364, 0.2677, 0.3305, 0.1654]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.091468</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>[0.0283, 0.0586, 0.1633, 0.7498]</td>\n",
       "      <td>[[0.0, 0.0, 0.1043, 0.8957], [0.0, 0.0, 0.1461, 0.8539], [0.0, 0.0, 0.1482, 0.8518], [0.0, 0.0, 0.1452, 0.8548], [0.0, 0.0, 0.1591, 0.8409], [0.0, 0.0, 0.1575, 0.8425], [0.0, 0.0002, 0.1171, 0.8827], [0.0007, 0.0, 0.1161, 0.8832], [0.0005, 0.0835, 0.1418, 0.7742], [0.0182, 0.1334, 0.2386, 0.6097], [0.1121, 0.1961, 0.191, 0.5008], [0.2086, 0.2893, 0.2949, 0.2072]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.095314</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>[0.0351, 0.0548, 0.1486, 0.7615]</td>\n",
       "      <td>[[0.0, 0.0, 0.0717, 0.9283], [0.0, 0.0, 0.1025, 0.8975], [0.0, 0.0001, 0.1124, 0.8875], [0.0, 0.0, 0.1122, 0.8878], [0.0, 0.0, 0.1154, 0.8846], [0.0, 0.0, 0.1127, 0.8873], [0.0, 0.0, 0.1147, 0.8853], [0.0001, 0.0, 0.1134, 0.8865], [0.0357, 0.0728, 0.0935, 0.7981], [0.0644, 0.1224, 0.2104, 0.6029], [0.0435, 0.2355, 0.2492, 0.4718], [0.2772, 0.2269, 0.3755, 0.1204]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.090598</td>\n",
       "      <td>0.970093</td>\n",
       "      <td>[0.0468, 0.0508, 0.162, 0.7404]</td>\n",
       "      <td>[[0.0, 0.0, 0.1331, 0.8669], [0.0, 0.0, 0.0957, 0.9043], [0.0, 0.0, 0.1353, 0.8647], [0.0, 0.0, 0.153, 0.847], [0.0, 0.0, 0.147, 0.853], [0.0, 0.0002, 0.1476, 0.8523], [0.0356, 0.0141, 0.0993, 0.8511], [0.0001, 0.0, 0.119, 0.8809], [0.0056, 0.0417, 0.0923, 0.8603], [0.2126, 0.0686, 0.1847, 0.5341], [0.1676, 0.1093, 0.238, 0.4851], [0.1399, 0.3757, 0.3995, 0.085]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.090955</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>[0.0331, 0.0827, 0.1682, 0.716]</td>\n",
       "      <td>[[0.0, 0.0, 0.197, 0.803], [0.0, 0.0, 0.1754, 0.8246], [0.0, 0.1452, 0.06, 0.7949], [0.0, 0.0, 0.1255, 0.8745], [0.0, 0.0, 0.1321, 0.8679], [0.001, 0.0003, 0.1342, 0.8645], [0.0087, 0.0001, 0.1146, 0.8766], [0.0043, 0.0, 0.1105, 0.8852], [0.0, 0.1402, 0.1367, 0.7231], [0.2216, 0.0804, 0.2329, 0.4651], [0.0396, 0.2399, 0.233, 0.4875], [0.1219, 0.3867, 0.3665, 0.1249]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.089707</td>\n",
       "      <td>0.970539</td>\n",
       "      <td>[0.0717, 0.0455, 0.166, 0.7168]</td>\n",
       "      <td>[[0.0, 0.0, 0.1398, 0.8602], [0.0, 0.0, 0.145, 0.855], [0.0, 0.0, 0.1354, 0.8646], [0.0, 0.0, 0.1378, 0.8622], [0.0, 0.0, 0.1665, 0.8335], [0.0, 0.0006, 0.1629, 0.8365], [0.0203, 0.0013, 0.1212, 0.8573], [0.0005, 0.0, 0.115, 0.8845], [0.0191, 0.1317, 0.1235, 0.7257], [0.3022, 0.0962, 0.1487, 0.4529], [0.1514, 0.2088, 0.2383, 0.4015], [0.3674, 0.1079, 0.3575, 0.1672]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.970517</td>\n",
       "      <td>[0.0274, 0.0652, 0.1692, 0.7382]</td>\n",
       "      <td>[[0.0, 0.0, 0.1121, 0.8879], [0.0, 0.0, 0.1291, 0.8709], [0.0086, 0.016, 0.1148, 0.8607], [0.0, 0.0, 0.1461, 0.8539], [0.0, 0.0, 0.1366, 0.8634], [0.0002, 0.0494, 0.2336, 0.7168], [0.0008, 0.0, 0.1154, 0.8838], [0.0002, 0.0, 0.115, 0.8848], [0.0022, 0.0899, 0.1187, 0.7891], [0.133, 0.1153, 0.2713, 0.4803], [0.0622, 0.1433, 0.2284, 0.566], [0.1216, 0.3689, 0.3094, 0.2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.093142</td>\n",
       "      <td>0.969351</td>\n",
       "      <td>[0.0418, 0.0615, 0.1722, 0.7244]</td>\n",
       "      <td>[[0.0, 0.0, 0.1184, 0.8816], [0.0, 0.0, 0.1361, 0.8639], [0.0008, 0.0002, 0.1467, 0.8523], [0.0, 0.0, 0.1233, 0.8767], [0.0, 0.0004, 0.1362, 0.8634], [0.0006, 0.0223, 0.1419, 0.8352], [0.0209, 0.0002, 0.1208, 0.8581], [0.0026, 0.0, 0.1183, 0.8792], [0.0095, 0.1165, 0.11, 0.764], [0.2037, 0.1319, 0.2416, 0.4228], [0.0748, 0.1643, 0.2858, 0.4752], [0.1892, 0.3024, 0.3878, 0.1206]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.089364</td>\n",
       "      <td>0.970872</td>\n",
       "      <td>[0.0292, 0.0763, 0.1689, 0.7256]</td>\n",
       "      <td>[[0.0, 0.0, 0.0914, 0.9086], [0.0123, 0.0, 0.1418, 0.8459], [0.0043, 0.0237, 0.1038, 0.8682], [0.0009, 0.0, 0.1157, 0.8834], [0.0, 0.0, 0.1201, 0.8799], [0.0122, 0.0027, 0.1144, 0.8708], [0.0122, 0.0, 0.1157, 0.8721], [0.0001, 0.0, 0.1163, 0.8836], [0.0015, 0.1285, 0.1232, 0.7468], [0.0678, 0.1938, 0.2873, 0.4511], [0.0667, 0.2283, 0.3132, 0.3919], [0.172, 0.3388, 0.3837, 0.1054]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.089450</td>\n",
       "      <td>0.970971</td>\n",
       "      <td>[0.0298, 0.0576, 0.1849, 0.7277]</td>\n",
       "      <td>[[0.0001, 0.0, 0.1365, 0.8634], [0.0, 0.0, 0.1473, 0.8527], [0.0069, 0.0092, 0.1474, 0.8365], [0.0, 0.0, 0.1346, 0.8654], [0.0, 0.0001, 0.1397, 0.8603], [0.0062, 0.0004, 0.1369, 0.8565], [0.0259, 0.0, 0.1122, 0.8619], [0.0, 0.0, 0.1098, 0.8902], [0.0021, 0.1051, 0.1294, 0.7633], [0.0924, 0.0406, 0.2443, 0.6227], [0.0509, 0.2247, 0.4168, 0.3076], [0.1729, 0.3107, 0.3641, 0.1523]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.093437</td>\n",
       "      <td>0.969306</td>\n",
       "      <td>[0.0375, 0.0696, 0.1657, 0.7272]</td>\n",
       "      <td>[[0.0, 0.0, 0.1391, 0.8609], [0.0, 0.0, 0.1511, 0.8489], [0.0034, 0.0003, 0.1187, 0.8777], [0.0, 0.0, 0.1103, 0.8897], [0.0, 0.0097, 0.0969, 0.8935], [0.0012, 0.0041, 0.1327, 0.862], [0.0097, 0.0, 0.1067, 0.8836], [0.002, 0.0001, 0.1044, 0.8936], [0.0064, 0.0936, 0.1121, 0.7879], [0.1484, 0.1433, 0.2469, 0.4614], [0.0458, 0.3181, 0.3187, 0.3174], [0.2338, 0.266, 0.3508, 0.1494]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.088883</td>\n",
       "      <td>0.971160</td>\n",
       "      <td>[0.0557, 0.051, 0.1694, 0.7239]</td>\n",
       "      <td>[[0.0, 0.0, 0.1339, 0.8661], [0.0, 0.0, 0.1187, 0.8813], [0.0052, 0.004, 0.1135, 0.8774], [0.0, 0.0058, 0.0982, 0.896], [0.0, 0.0, 0.1265, 0.8734], [0.0068, 0.0001, 0.1173, 0.8758], [0.0203, 0.0002, 0.1176, 0.8619], [0.0034, 0.0003, 0.1154, 0.8809], [0.0208, 0.1569, 0.1202, 0.7021], [0.1811, 0.1305, 0.2166, 0.4717], [0.1335, 0.1142, 0.365, 0.3873], [0.2972, 0.1997, 0.3902, 0.1129]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>0.091693</td>\n",
       "      <td>0.970766</td>\n",
       "      <td>[0.0371, 0.062, 0.1658, 0.735]</td>\n",
       "      <td>[[0.0, 0.0, 0.1939, 0.8061], [0.0, 0.0, 0.1037, 0.8963], [0.0062, 0.0, 0.1289, 0.865], [0.0, 0.0, 0.1345, 0.8655], [0.0, 0.0016, 0.1387, 0.8597], [0.0012, 0.003, 0.1413, 0.8546], [0.0165, 0.0002, 0.1149, 0.8684], [0.0039, 0.0, 0.1094, 0.8866], [0.0093, 0.1254, 0.1226, 0.7427], [0.1104, 0.1716, 0.2016, 0.5164], [0.0481, 0.1875, 0.3014, 0.4631], [0.25, 0.2551, 0.2987, 0.1962]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.092237</td>\n",
       "      <td>0.969858</td>\n",
       "      <td>[0.0639, 0.0464, 0.1495, 0.7402]</td>\n",
       "      <td>[[0.0, 0.0, 0.116, 0.884], [0.0066, 0.0, 0.1273, 0.8661], [0.0205, 0.0015, 0.1202, 0.8578], [0.0, 0.0, 0.1187, 0.8813], [0.0, 0.0012, 0.1057, 0.8931], [0.0043, 0.0017, 0.1057, 0.8883], [0.0073, 0.0049, 0.1053, 0.8825], [0.0016, 0.0, 0.1008, 0.8976], [0.0059, 0.1363, 0.1135, 0.7443], [0.246, 0.0709, 0.2789, 0.4042], [0.1612, 0.1512, 0.3488, 0.3387], [0.3131, 0.1889, 0.1534, 0.3447]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.087919</td>\n",
       "      <td>0.971424</td>\n",
       "      <td>[0.0521, 0.0552, 0.1638, 0.7289]</td>\n",
       "      <td>[[0.0, 0.0, 0.1269, 0.8731], [0.0039, 0.0, 0.1192, 0.877], [0.006, 0.0214, 0.0874, 0.8852], [0.0, 0.0, 0.1243, 0.8757], [0.0, 0.0, 0.1437, 0.8563], [0.0029, 0.0005, 0.1405, 0.8561], [0.0293, 0.0007, 0.12, 0.85], [0.0001, 0.0, 0.1042, 0.8957], [0.0186, 0.1555, 0.1357, 0.6902], [0.1843, 0.0959, 0.2557, 0.4641], [0.1218, 0.139, 0.2698, 0.4694], [0.2585, 0.2493, 0.3382, 0.154]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>0.969919</td>\n",
       "      <td>[0.0534, 0.0763, 0.1647, 0.7056]</td>\n",
       "      <td>[[0.0, 0.0, 0.1104, 0.8896], [0.0007, 0.0, 0.1308, 0.8684], [0.0206, 0.0022, 0.1283, 0.8488], [0.0, 0.0, 0.1297, 0.8703], [0.0, 0.0001, 0.1462, 0.8537], [0.041, 0.2082, 0.126, 0.6248], [0.0374, 0.0, 0.1304, 0.8322], [0.0023, 0.0, 0.121, 0.8766], [0.0519, 0.1475, 0.1124, 0.6883], [0.1683, 0.0272, 0.3749, 0.4296], [0.0698, 0.2776, 0.2515, 0.4011], [0.2486, 0.2529, 0.2144, 0.2842]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.093614</td>\n",
       "      <td>0.969631</td>\n",
       "      <td>[0.0625, 0.061, 0.1539, 0.7225]</td>\n",
       "      <td>[[0.0006, 0.0, 0.1201, 0.8793], [0.0, 0.0, 0.1523, 0.8477], [0.0359, 0.0414, 0.0987, 0.824], [0.0, 0.0, 0.1365, 0.8635], [0.0, 0.0001, 0.1481, 0.8519], [0.0478, 0.0352, 0.1229, 0.7942], [0.0445, 0.0, 0.1227, 0.8327], [0.0113, 0.0, 0.1114, 0.8772], [0.0411, 0.1496, 0.1134, 0.6959], [0.2373, 0.075, 0.2287, 0.459], [0.1216, 0.141, 0.2198, 0.5176], [0.2097, 0.2901, 0.2726, 0.2277]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.093084</td>\n",
       "      <td>0.969843</td>\n",
       "      <td>[0.0624, 0.0572, 0.1715, 0.7088]</td>\n",
       "      <td>[[0.0, 0.0, 0.085, 0.915], [0.0041, 0.0, 0.1138, 0.8821], [0.0331, 0.0037, 0.1156, 0.8476], [0.0, 0.0043, 0.141, 0.8547], [0.0, 0.0, 0.1353, 0.8647], [0.0292, 0.0207, 0.1204, 0.8297], [0.0319, 0.0002, 0.1226, 0.8453], [0.0029, 0.0011, 0.1195, 0.8766], [0.0207, 0.1251, 0.1269, 0.7273], [0.287, 0.0697, 0.2668, 0.3766], [0.1128, 0.179, 0.3718, 0.3365], [0.2272, 0.2829, 0.34, 0.15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.970237</td>\n",
       "      <td>[0.0625, 0.0551, 0.1623, 0.7201]</td>\n",
       "      <td>[[0.0, 0.0, 0.1089, 0.8911], [0.0127, 0.0, 0.1026, 0.8847], [0.0301, 0.0015, 0.1079, 0.8605], [0.0, 0.0, 0.1354, 0.8646], [0.0, 0.0, 0.1401, 0.8599], [0.0242, 0.0019, 0.1229, 0.851], [0.031, 0.0271, 0.0866, 0.8554], [0.0037, 0.0, 0.1118, 0.8845], [0.0349, 0.1579, 0.108, 0.6992], [0.2388, 0.058, 0.3232, 0.38], [0.0851, 0.2081, 0.2741, 0.4326], [0.2899, 0.2068, 0.3256, 0.1777]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.104172</td>\n",
       "      <td>0.965084</td>\n",
       "      <td>[0.0523, 0.0678, 0.173, 0.7069]</td>\n",
       "      <td>[[0.0, 0.0, 0.136, 0.864], [0.0004, 0.0, 0.1471, 0.8525], [0.0397, 0.0282, 0.1038, 0.8283], [0.0207, 0.0167, 0.1038, 0.8588], [0.0, 0.0, 0.1354, 0.8646], [0.0325, 0.0027, 0.1205, 0.8443], [0.0287, 0.019, 0.1007, 0.8517], [0.0131, 0.0002, 0.1119, 0.8748], [0.0484, 0.2249, 0.1017, 0.625], [0.1093, 0.1376, 0.2903, 0.4628], [0.0594, 0.1593, 0.386, 0.3953], [0.2752, 0.2254, 0.3383, 0.1611]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-6000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-10000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-16000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-22000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-26000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-38000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-38000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-38000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-32000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000/special_tokens_map.json\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-42000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-42000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-42000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-52000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-44000 (score: 0.08791884986253885).\n",
      "Deleting older checkpoint [/home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/config.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/generation_config.json\n",
      "Model weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/pytorch_model.bin\n",
      "tokenizer config file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/tokenizer_config.json\n",
      "Special tokens file saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/special_tokens_map.json\n",
      "Configuration saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/trained_head/gating/head_config.json\n",
      "Module weights saved in /home/jaehan/research/adapter/adapter-poisoning/data_ign/case2_sts_moeBaseline_tmp/gating_20231123-104626/trained_head/gating/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        6.54\n",
      "  total_flos               = 222384486GF\n",
      "  train_loss               =      0.1071\n",
      "  train_runtime            =  6:22:57.47\n",
      "  train_samples_per_second =     460.192\n",
      "  train_steps_per_second   =       7.191\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "\n",
    "loss_history = {'max_seq_length': max_seq_length,\n",
    "                'random_seed': random_seed,\n",
    "                'lr': learning_rate,\n",
    "                'warmup_ratio': warmup_ratio,\n",
    "                'early_stopping_patience': patience,\n",
    "                'total_batch_size': total_batch_size_train,\n",
    "                'num_train_epoch': num_train_epochs,\n",
    "                'task_list': task_list,\n",
    "                'adapter_list': adapter_list,\n",
    "                'adapter_k': adapter_k,\n",
    "                'noisy_gating': noisy_gating,\n",
    "                'alpha_info': alpha_info}\n",
    "\n",
    "\n",
    "with open(os.path.join(output_dir, \"hyperparameters.json\"), \"w\") as f:\n",
    "    json.dump(loss_history, f)\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "os.makedirs(os.path.join(output_dir, f\"trained_head\"), exist_ok=True)\n",
    "model.save_head(os.path.join(output_dir, f\"trained_head/{task_name_str}\"), task_name_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aed3544-4d5a-4f76-b82f-ddbbb680d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6.54,\n",
      " 'eval_accuracy': 0.8777599930763245,\n",
      " 'eval_freq_all': [[0.0, 0.0, 0.0012, 0.9988],\n",
      "                   [0.1041, 0.0, 0.049, 0.8469],\n",
      "                   [0.1537, 0.0035, 0.0002, 0.8426],\n",
      "                   [0.0, 0.0, 0.1715, 0.8285],\n",
      "                   [0.0, 0.0, 0.6102, 0.3898],\n",
      "                   [0.0749, 0.0, 0.5222, 0.4029],\n",
      "                   [0.7437, 0.0001, 0.0056, 0.2506],\n",
      "                   [0.0, 0.0, 0.0001, 0.9999],\n",
      "                   [0.4618, 0.0128, 0.3036, 0.2218],\n",
      "                   [0.8533, 0.0395, 0.0603, 0.0469],\n",
      "                   [0.9414, 0.0008, 0.0329, 0.025],\n",
      "                   [0.58, 0.0107, 0.2303, 0.179]],\n",
      " 'eval_freq_avg': [0.3261, 0.0056, 0.1656, 0.5027],\n",
      " 'eval_loss': 0.2890433233976364,\n",
      " 'eval_runtime': 55.7522,\n",
      " 'eval_samples_per_second': 448.413,\n",
      " 'eval_steps_per_second': 0.448}\n",
      "{'epoch': 6.54,\n",
      " 'eval_accuracy': 0.9118198752403259,\n",
      " 'eval_freq_all': [[0.0, 0.0, 0.7205, 0.2795],\n",
      "                   [0.0, 0.0, 0.8659, 0.1341],\n",
      "                   [0.0038, 0.5694, 0.1698, 0.257],\n",
      "                   [0.0, 0.0, 0.9456, 0.0544],\n",
      "                   [0.0, 0.0, 0.9747, 0.0253],\n",
      "                   [0.0, 0.0, 0.9765, 0.0235],\n",
      "                   [0.0131, 0.0, 0.9681, 0.0188],\n",
      "                   [0.0019, 0.0, 0.622, 0.3762],\n",
      "                   [0.0056, 0.0075, 0.9747, 0.0122],\n",
      "                   [0.0553, 0.5741, 0.3565, 0.0141],\n",
      "                   [0.4381, 0.0066, 0.5216, 0.0338],\n",
      "                   [0.3021, 0.2955, 0.0197, 0.3827]],\n",
      " 'eval_freq_avg': [0.0683, 0.1211, 0.6763, 0.1343],\n",
      " 'eval_loss': 0.26249976456165314,\n",
      " 'eval_runtime': 2.3779,\n",
      " 'eval_samples_per_second': 448.296,\n",
      " 'eval_steps_per_second': 0.841}\n",
      "{'epoch': 6.54,\n",
      " 'eval_accuracy': 0.9277523159980774,\n",
      " 'eval_freq_all': [[0.0, 0.0, 0.7649, 0.2351],\n",
      "                   [0.0, 0.0, 0.8796, 0.1204],\n",
      "                   [0.0034, 0.5642, 0.1823, 0.25],\n",
      "                   [0.0, 0.0, 0.9553, 0.0447],\n",
      "                   [0.0, 0.0, 0.9817, 0.0183],\n",
      "                   [0.0, 0.0, 0.9874, 0.0126],\n",
      "                   [0.0046, 0.0011, 0.9839, 0.0103],\n",
      "                   [0.0023, 0.0, 0.6617, 0.336],\n",
      "                   [0.0034, 0.0126, 0.9782, 0.0057],\n",
      "                   [0.0528, 0.6032, 0.3349, 0.0092],\n",
      "                   [0.3853, 0.0023, 0.5768, 0.0356],\n",
      "                   [0.2867, 0.3291, 0.0195, 0.3647]],\n",
      " 'eval_freq_avg': [0.0615, 0.1261, 0.6922, 0.1202],\n",
      " 'eval_loss': 0.21652789413928986,\n",
      " 'eval_runtime': 1.9627,\n",
      " 'eval_samples_per_second': 444.275,\n",
      " 'eval_steps_per_second': 0.509}\n",
      "{'epoch': 6.54,\n",
      " 'eval_accuracy': 0.9565526247024536,\n",
      " 'eval_freq_all': [[0.0, 0.0, 0.0269, 0.9731],\n",
      "                   [0.0, 0.0, 0.0095, 0.9905],\n",
      "                   [0.0, 0.0025, 0.0032, 0.9943],\n",
      "                   [0.0, 0.0, 0.0068, 0.9932],\n",
      "                   [0.0, 0.0, 0.0082, 0.9918],\n",
      "                   [0.0001, 0.0008, 0.0083, 0.9908],\n",
      "                   [0.0008, 0.0008, 0.0067, 0.9917],\n",
      "                   [0.0, 0.0, 0.0023, 0.9977],\n",
      "                   [0.0008, 0.1824, 0.0142, 0.8025],\n",
      "                   [0.1763, 0.0744, 0.206, 0.5432],\n",
      "                   [0.0765, 0.1587, 0.2128, 0.552],\n",
      "                   [0.2597, 0.2278, 0.3868, 0.1256]],\n",
      " 'eval_freq_avg': [0.0429, 0.054, 0.0743, 0.8289],\n",
      " 'eval_loss': 0.12312624025109567,\n",
      " 'eval_runtime': 84.8317,\n",
      " 'eval_samples_per_second': 447.946,\n",
      " 'eval_steps_per_second': 0.448}\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {}\n",
    "for task_name, eval_dataset in zip(task_list, eval_dataset_list):\n",
    "    metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "    pprint(metrics)\n",
    "    metrics_dict[task_name] = metrics\n",
    "trainer.save_metrics(\"eval\", metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53427fb5-595a-49be-8bce-688267001416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input('Remove files?\\n')\n",
    "# import shutil\n",
    "# directory_path = output_dir\n",
    "# shutil.rmtree(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d4361-cec6-4280-ba9f-1c772ffeadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f08ba-7e92-4600-aee4-0ec29ca08b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "pytorch2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
